<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>AIART2024</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <!-- <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
  <link
    href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800'
    rel='stylesheet' type='text/css'>
  <link
    href='https://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic'
    rel='stylesheet' type='text/css'>

  <!-- Plugin CSS -->
  <link href="vendor/magnific-popup/magnific-popup.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/creative.min.css" rel="stylesheet">
  <link rel="icon" type="images/png" href="images/logo1.png">

</head>

<body id="page-top">

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
    <div class="container">
      <a class="navbar-brand js-scroll-trigger" href="#page-top"><img src="images/logo.png" style="height: 50px;" /></a>
      <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse"
        data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false"
        aria-label="Toggle navigation">

        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#cfp">Call for Papers</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#dates">Dates</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#keynotes">Keynotes</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#program">Conference Program</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#ps">Technical Program Committee</a>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#ppl">Organizers</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#history">History</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#MIR">Partner</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#sponsorship">Sponsorship</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <header class="masthead text-center text-white d-flex">
    <div class="container my-auto">
      <div class="row">
        <div class="col-lg-10 mx-auto">
          <!-- <h2 class="text-uppercase"> -->
          <h2 style="font-size: 36px">
            <strong>The 6<sup>th</sup> IEEE Workshop on <br />
              <a href="https://2024.ieeeicme.org/" target="_blank" style="color: white">Artificial Intelligence for
                Art Creation</strong></a>
          </h2>
          <hr>
        </div>
        <div class="col-lg-8 mx-auto">
          <p class="text-faded mb-5" style="font-size: 24px; font-weight: bold;">Niagra Falls, Canada<br />July 15-19, 2024<br />
            Jointly with <a href="https://2024.ieeeicme.org/" target="_blank" style="color: white"><u>ICME
                2024</u></a>
            <br>
          </p>
        </div>
      </div>
    </div>
  </header>

  <section class="bg-primary" id="cfp">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading text-white">Call for Papers</h2>
          <hr class="light my-4">
          <p class="text-faded mb-4" style="text-align: justify; color: white; font-size: 18px">
            Recent advances of AI-Generated Content (AIGC) have been an innovative engine for digital content generation. As an ever increasingly powerful tool, AI has gained great popularity across the whole spectrum of art, such as AI painting, composing, writing, virtual hosting, fashion, design, etc. Tools like Sora even demonstrates the ability to model and simulate the physical world. An era of AI-generated videos or movies is coming. Moreover, AI is also capable of understanding art, and evaluating the aesthetic value of art as well. AI has not only exhibited creativity to some extent, but also served as an enabling tool to discover the principles underneath creativity and imagination, which are traditional challenges for neuroscience, cognitive science, and psychology. Despite all these promising features of AI for Art, we still have to face the many challenges such as the explainability of generative models and the copyright issues of AI art works.
          </p>

          <p class="text-faded mb-4" style="text-align: justify; color: white; font-size: 18px">
            This is the 6<sup>th</sup> AIART workshop to be held in conjunction with ICME 2024 in Niagara Falls, Canada, and it aims to bring forward cutting-edge technologies and most recent advances in the area of AI art in terms of enabling creation, analysis, understanding, and rendering technologies.
          </p>

          <p class="text-faded mb-4" style="text-align: justify; color: white; font-size: 18px">
            The theme topic of AIART 2024 will be <strong>Big Models for Art Creation</strong>. We plan to invite 3 keynote speakers to present their insightful perspectives on AI art.
          </p>
          <p class="text-faded mb-4" style="text-align: justify; color: white; font-size: 18px">
            We sincerely invite high-quality papers presenting or addressing issues related to AI art, including but not limited to the following topics:
          </p>
          <ul style="color: white">
            <li>
              <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                Affective computing for AI Art
              </div>
            </li>
            <li>
              <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                Theory and practice of AI creativity
              </div>
            </li>
            <li>
              <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                Neuroscience, cognitive science and psychology for AI Art
              </div>
            </li>
            <li>
              <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                AI Art for metaverse
              </div>
            </li>
            <li>
              <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                AI for painting generation
              </div>
            </li>
            <li>
              <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                AI for 3D content generation
              </div>
            </li>
            <li>
            <li>
              <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                AI for 3D content generation
              </div>
            </li>
            <li>
              <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                AI for video and movie
              </div>
            </li>
            <li>
              <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
              AI for cultural heritage
              </div>
            </li>
            <li>
              <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                AI for sound synthesis, music composition, performance, and instrument design
              </div>
            </li>
            <li>
              <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                AI for poem composing and synthesis
              </div>
            </li>
            <li>
              <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                AI for typography and graphic design
              </div>
            </li>
            <li>
              <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                AI for fashion, makeup, and virtual hosting
              </div>
            </li>
            <li>
              <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                AI for multimodal and cross-modal art generation
              </div>
            </li>
            <li>
              <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                AI for art style transfer
              </div>
            </li>
            <li>
              <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                AI for aesthetics understanding, analysis, assessment and prediction
              </div>
            </li>
            <li>
              <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                Authentication and copyright issues of AI artworks
              </div>
            </li>
          </ul>
          <br>
          <br>
          <p class="text-faded mb-4; " style="text-align: left; color: white; font-size: 18px">
            The authors of selected high-quality papers will be invited to submit an extended version to the Machine Intelligence Research (MIR) journal published by Springer.
          </p>

          <p class="text-faded mb-4; " style="text-align: left; color: white; font-size: 18px">
            Additionally, one Best Paper Award will be given.
          </p>

          <p class="text-faded mb-4; " style="text-align: left; color: white; font-size: 18px">
            AIART 2024 is also launching a demo track for artists to showcase their creative artworks in the form of in-person or online gallery. The demo track will provide a great opportunity for people to experience interactive artworks and communicate creative ideas. The submission guideline for the demo track follows
            that of the main ICME conference: <a href="https://2024.ieeeicme.org/author-information-and-submission-instructions/"
              target="_blank">https://2024.ieeeicme.org/author-information-and-submission-instructions/</a>.
          </p>

          <br>
          <br>
          <p class="text-faded mb-4; " style="text-align: left; color: white; font-size: 24px">
            Paper Submission
          </p>
          <p class="text-faded mb-4; " style="text-align: left; color: white; font-size: 18px">
            Authors should prepare their manuscript according to the Guide for Authors of ICME available at Author
            Information and Submission Instructions: <a href="https://2024.ieeeicme.org/author-information-and-submission-instructions/"
              target="_blank">https://2024.ieeeicme.org/author-information-and-submission-instructions/</a>
          </p>
          <p class="text-faded mb-4; " style="text-align: left; color: white; font-size: 18px">
            Submission address: <a href="https://cmt3.research.microsoft.com/ICMEW2024"
              target="_blank">https://cmt3.research.microsoft.com/ICMEW2024</a>
          </p>

          <!-- <p class="text-faded mb-4; " style="text-align: left; color: white; font-size: 18px" >
              Submission address: <a href="http://2023.ieeeicme.org/author-info.html"  target="_blank" >http://2023.ieeeicme.org/author-info.html</a>
            </p> -->

          <br>
          <a class="btn btn-light btn-xl js-scroll-trigger" href="https://cmt3.research.microsoft.com/ICMEW2024"
            target="_blank">Submit link</a>
        </div>
      </div>
    </div>
  </section>

  <section id="dates">
    <div class="container">
      <div class="row">
        <div class="col-lg-6 mx-auto text-center">
          <h2 class="section-heading">Important Dates</h2>
          <hr class="dark my-4">
          <table width="100%" cellpadding="10" align="center">
            <tr>
              <td>
                <div class="text-muted" style="text-align: left; font-weight: bold;">Submissions due</div>
              </td>
              <td>
                <div class="text-muted" style="text-align: left;">April 6, 2024</div>
              </td>
            </tr>
            <tr>
              <td>
                <div class="text-muted" style="text-align: left; font-weight: bold;">Workshop date</div>
              </td>
              <td>
                <div class="text-muted" style="text-align: left;">TBD</div>
              </td>
            </tr>


          </table>
          <!-- <a class="btn btn-light btn-xl js-scroll-trigger" href="#services">Get Started!</a> -->
        </div>
      </div>
    </div>
  </section>


  <!-- first -->
  <!-- <section class="bg-primary" id="keynotes">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading text-white">Keynotes (1/5)</h2>
          <hr class="dark my-4">

          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 26px;">
            Keynote 1
          </p>
          <br>
          <div style="float:right; clear:both; top:30px;">
            <img src="images/Brian.jpeg" style="height: 200px; border-radius: 10px;" />
          </div>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Speaker:
          </p>

          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            Brian C. Lovell
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Title:
          </p>

          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            Synthesizing Faces for Ethical Face Recognition using Stable Diffusion
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Time:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            8:35 – 9:05, July 14, 2023
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Abstract:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            We propose a solution to address ethical concerns in face recognition databases by synthesizing faces to
            replace internet-scraped photographs without consent. Our approach utilizes generative techniques, including
            StyleGAN and Stable Diffusion. StyleGAN generates diverse and realistic synthetic faces by learning from
            extensive data, allowing control over facial attributes for demographic alignment. Stable Diffusion models
            image generation dynamics, producing high-quality, visually coherent synthetic faces. Our solution preserves
            database functionality while respecting privacy. Through evaluations, we assess visual quality, diversity,
            and demographic fairness of synthesized faces. Compatibility and effectiveness in face recognition tasks are
            also evaluated to maintain system accuracy and robustness. Our research highlights the potential of ethical
            face synthesis for creating privacy-preserving face recognition databases.

          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Biography:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            Brian C. Lovell was born in Brisbane, Australia in 1960. He received the BE in electrical engineering in
            1982, the BSc in computer science in 1983, and the PhD in signal processing in 1991: all from the University
            of Queensland (UQ). Professor Lovell is Director of the Advanced Surveillance Group in the School of ITEE,
            UQ. He was President of the International Association for Pattern Recognition (IAPR) [2008-2010], and is
            Fellow of the IAPR, Senior Member of the IEEE, and voting member for Australia on the Governing Board of the
            IAPR. He was General Co-Chair of the IEEE International Conference on Image Processing (ICIP) in Melbourne,
            2013, Program Co-Chair of the International Conference of Pattern Recognition (ICPR) in Cancun, 2016, and
            Program Co-Chair of ICPR2020 in Milan. His interests include Artificial Intelligence, Computer Vision,
            non-cooperative Face Recognition, Biometrics, and Pattern Recognition.
          </p>

        </div>
      </div>
    </div>
  </section> -->

  <!-- second -->
  <!-- <section id="keynotes">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading">Keynotes (2/5)</h2>
          <hr class="dark my-4">

          <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 26px;">
            Keynote 2
          </p>
          <br>
          <div style="float:right; clear:both; top:30px;">
            <img src="images/Leida_Li.jpg" style="height: 250px; border-radius: 10px;" />
          </div>
          <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
            Speaker:
          </p>

          <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
            Leida Li
          </p>
          <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
            Title:
          </p>

          <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
            Perception and Assessment of Image Aesthetics: Recent Advances and New Thinking
          </p>
          <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
            Time:
          </p>
          <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
            11:00 – 12:00, July 14, 2023
          </p>
          <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
            Abstract:
          </p>
          <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
            With the explosive growth of digital images produced by low-cost built-in cameras, image aesthetics
            assessment (IAA) has become an increasing popular research topic in both academia and industry. IAA has wide
            applications in art design, smart photography, photo editing, etc. In this talk, the latest research
            progresses on IAA will be introduced, including both generic and personalized IAA. Multi-modal IAA will also
            be introduced in the context of large vision-language models. We will also discuss research challenges and
            future trends on image aesthetics research.
          </p>
          <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
            Biography:
          </p>
          <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
            Leida Li received the B.Sc. and Ph.D. degrees from Xidian University in 2004 and 2009, respectively. From
            2014 to 2015, he was a Research Fellow with the Rapid-rich Object SEarch (ROSE) Lab, Nanyang Technological
            University (NTU), Singapore, where he was a Senior Research Fellow from 2016 to 2017. From 2009 to 2019, he
            worked as Lecturer, Associate Professor and Professor, in the School of Information and Control Engineering,
            China University of Mining and Technology, China. Currently, he is a Full Professor with the School of
            Artificial Intelligence, Xidian University, China. His research interests include image/video quality
            evaluation, computational aesthetics and visual emotion analysis. His research is funded by NSFC, OPPO,
            Huawei and Tencent, etc. He has published more than 100 papers in these areas. He is on the editor board of
            Journal of Visual Communication and Image Representation (Best Associate Editor Award 2021), EURASIP Journal
            on Image and Video Processing and Journal of Image and Graphics (Excellent Editor Award 2022). He is a
            senior member of CCF and CSIG.
          </p>

        </div>
      </div>
    </div>
  </section> -->

  <!-- third -->
  <!-- <section class="bg-primary" id="keynotes">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading text-white">Keynotes (3/5)</h2>
          <hr class="dark my-4">

          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 26px;">
            Keynote 3
          </p>
          <br>
          <div style="float:right; clear:both; top:30px;">
            <img src="images/kang_zhang.png" style="height: 200px; border-radius: 10px;" />
          </div>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Speaker:
          </p>

          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            Kang Zhang
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Title:
          </p>

          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            Creating a Massive Open Metaverse Course (MOMC)
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Time:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            13:30 – 14:00, July 14, 2023
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Abstract:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            Much effort has been made in using virtual reality (VR) technology to support massive open online course
            (MOOC) environments. This talk briefly reviews the latest research in VR/AR/XR application in education, and
            argues how immersive virtual educational experiences could be gained. We then introduce the new concept of
            Massive Open Metaverse Course (MOMC), combining MOOC and Metaverse and utilizing the latest volumetric video
            technology. We offer our vision on dual campus online education for HKUST 2.0, with a real case study, i.e.,
            the President’s First Lecture, under development at the Guangzhou campus. This is the world’s first true
            MOMC environment, providing immersive and realistic virtual and augmented reality experiences to both
            teachers and learners.
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Biography:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            Kang Zhang is Acting Head and Professor of Computational Media and Arts, Information Hub, Hong Kong
            University of Science and Technology (Guangzhou), Professor of Division of Emerging Interdisciplinary Areas,
            HKUST, and Professor Emeritus of Computer Science, The University of Texas at Dallas. He was a Fulbright
            Distinguished Chair and an ACM Distinguished Speaker, and held academic positions in China, the UK,
            Australia and USA. Zhang's current research interests include computational aesthetics, visual languages,
            and generative art and design; and has published 8 books, and over 120 journal papers in these areas. He has
            delivered keynotes at art and design, computer science, and management conferences, and is on the editorial
            boards of Journal of Big Data, The Visual Computer, Journal of Visual Language and Computing, International
            Journal of Software Engineering and Knowledge Engineering, International Journal of Advanced Intelligence,
            and Visual Computing for Industry, Biomedicine, and Art.

          </p>

        </div>
      </div>
    </div>
  </section> -->

  <!-- fourth -->
  <!-- <section id="keynotes">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading">Keynotes (4/5)</h2>
          <hr class="dark my-4">

          <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 26px;">
            Keynote 4
          </p>
          <br>
          <div style="float:right; clear:both; top:30px;">
            <img src="images/Bahareh_Nakisa.jpg" style="height: 250px; border-radius: 10px;" />
          </div>
          <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
            Speaker:
          </p>

          <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
            Bahareh Nakisa
          </p>
          <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
            Title:
          </p>

          <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
            Towards the wellbeing in space: measuring and monitoring the emotions of users immersed in meaningful
            virtual reality experiences
          </p>
          <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
            Time:
          </p>
          <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
            15:30 – 16:00, July 14, 2023
          </p>
          <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
            Abstract:
          </p>
          <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
            As the world advances in space exploration with current and planned stations in Low Earth Orbit (LEO), and
            long-duration missions to the Moon and Mars, a more diverse range of people will live and work in space.
            This increasing diversity in space exploration necessitates a deeper understanding of cultural context and
            diverse backgrounds when designing wellbeing solutions for astronauts. NASA identifies Five Hazards of Human
            Spaceflight: Radiation, Isolation and confinement, Distance from Earth, Gravity (or lack thereof), and
            Hostile/closed environments. Astronauts report challenges such as loneliness, boredom, disconnection,
            sensory deprivation, diminished cognitive performance, and stress while in orbit. In this talk we explore
            these challenges and how integrating extended reality (XR) environments, wearable sensors, and Artificial
            Intelligence can revolutionize astronauts' daily routines. We discuss how to mitigate environmental
            challenges and psychological stressors while promoting physical activity, motivation, and overall well-being
            in confined and isolated environment using advanced technologies.
          </p>
          <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
            Biography:
          </p>
          <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
            Dr. Bahareh Nakisa is a Lecturer of Applied AI and the course director of Applied AI at School of
            Information Technology, Deakin University, She received a B.Sc. degree in Soft Engineering from Iran in
            2008, Master of Computer Science from the National University of Malaysia in 2014, and a PhD in Computer
            Science (Artificial Intelligence) from the Queensland University of Technology (QUT), Australia in 2019. She
            started working in Industry as AI scientist and Lead AI scientist and then she joined School of Information
            Technology, Deakin University as a Lecturer of Applied AI in 2019. Her research interests are in the areas
            of artificial intelligence (AI), Deep learning, affective computing and time-series data analysis. She is
            particularly interested in the application of AI/DL models to solve real-world problems in applications such
            as healthcare, transportation, defence and space. She has published more than 39 publications in top-tier
            international venues in AI, computer science. She has secured more than AUD 2 million in external research
            and development funding.
          </p>
        </div>
      </div>
    </div>
  </section> -->

  <!-- fifth -->
  <!-- <section class="bg-primary" id="keynotes">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading text-white">Keynotes (5/5)</h2>
          <hr class="dark my-4">

          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 26px;">
            Keynote 5
          </p>
          <br>
          <div style="float:right; clear:both; top:30px;">
            <img src="images/liu_dong.jpg" style="height: 200px; border-radius: 10px;" />
          </div>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Speaker:
          </p>

          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            Dong Liu
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Title:
          </p>

          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            Controllable Image Synthesis with Diffusion Models
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Time:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            16:45 – 17:15, July 14, 2023
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Abstract:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            Diffusion models have demonstrated impressive capability in synthesizing photorealistic images given a few
            or even no words. These models may not fully satisfy user need, as normal users or artists intend to control
            the synthesized images with specific guidance, like overall layout, color, structure, object shape, and so
            on. We propose a method to adapt diffusion models for controllable image synthesis. Our method outperforms
            the existing methods and demonstrates multiple applications with its plausible generalization ability and
            flexible controllability.

          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Biography:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            Dong Liu received the B.S. and Ph.D. degrees in electrical engineering from the University of Science and
            Technology of China (USTC), Hefei, China, in 2004 and 2009, respectively. He was a Member of Research Staff
            with Nokia Research Center, Beijing, China, from 2009 to 2012. He joined USTC as a faculty member in 2012
            and became a Professor in 2020. His research interests include image and video processing, coding, analysis,
            and data mining. He has authored or co-authored more than 200 papers in international journals and
            conferences, which were cited more than 12000 times according to Google Scholar (h-index is 42). He has more
            than 30 granted patents. He has several technique proposals adopted by standardization groups. He received
            2009 IEEE TCSVT Best Paper Award, VCIP 2016 Best 10% Paper Award, and ISCAS 2022 Grand Challenge Top
            Creativity Paper Award. He is a Senior Member of IEEE, CCF, and CSIG, an elected member of MSA-TC of IEEE
            CAS Society, and an elected member of Multimedia TC of CSIG. He serves or had served as the Chair of IEEE
            1857.11 Standard Working Subgroup (also known as Future Video Coding Study Group), a Guest Editor for IEEE
            TCSVT, an Organizing Committee Member for VCIP 2022, ChinaMM 2022, ICME 2021, etc.
          </p>

        </div>
      </div>
    </div>
  </section> -->


  <!-- <section id="program">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading">Conference Program</h2>
          <hr class="dark my-4">
          <img src="images/aiart2023_program.png" style="max-width: 100%;" />
        </div>
      </div>
    </div>
  </section> -->



  <section class="bg-primary" id="ps">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading text-white">Technical Program Committee (Tentative)</h2>
          <hr class="light my-4">

          <h5 class="section-heading text-white" style="text-align: left; line-height: 1.8">
            <ul>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Ajay Kapur, California Institute of the Arts, USA
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Alan Chamberlain, University of Nottingham, Nottingham
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Alexander Lerch, Georgia Institute of Technology, USA
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Alexander Pantelyat, Johns Hopkins University, USA
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Bahareh Nakisa, Deakin University, Australia
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Baoqiang Han, China Conservatory of Music, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Baoyang Chen, Central Academy of Fine Arts, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Beici Liang, Tencent Music Entertainment Group, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Bing Li, King Abdullah University of Science and Technology, Saudi Arabia
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Björn W. Schuller, Imperial College London, UK
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Bob Sturm, KTH Royal Institute of Technology, Sweden
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Carlos Castellanos, Rochester Institute of Technology, USA
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Changsheng Xu, Institute of Automation, Chinese Academy of Sciences, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Dongmei Jiang, Northwestern Polytechnical University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Emma Young, BBC, UK
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Gus Xia, New York University Shanghai, China & Mohamed bin Zayed University of Artificial
                  Intelligence, United Arab Emirates
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Haifeng Li, Harbin Institute of Technology, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Haipeng Mi, Tsinghua University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Hongxun Yao, Harbin Institute of Technology, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Jesse Engel, Google, USA
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Jia Jia, Tsinghua University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Jianyu Fan, Microsoft, Canada
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Jing Wang, Beijing Institute of Technology, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  John See, Multimedia University, Malaysia
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Juan Huang, Johns Hopkins University, USA
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Junping Zhang, Fudan University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Kejun Zhang, Zhejiang University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Ke Lv, University of Chinese Academy of Sciences, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Kenneth Fields, Central Conservatory of Music, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Lai-Kuan Wong, Multimedia University, Malaysia
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Lamtharn Hanoi Hantrakul, ByteDance, USA
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Lei Xie, Northwestern Polytechnical University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Lin Gan, Tianjin University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Long Ye, China University of Communication, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Maosong Sun, Tsinghua University, China </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Mei Han, Ping An Technology Art institute, USA </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Mengjie Qi, China Conservatory of Music, China </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Ming Zhang, Nanjing Art College, China </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Mohammad Naim Rastgoo, Queensland University of Technology, Australia </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Na Qi, Beijing University of Technology, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Nick Bryan-Kinns, Queen Mary University of London, UK
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Nina Kraus, Northwestern University, USA
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Pengtao Xie, University of California, San Diego, USA
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Philippe Pasquier, Simon Fraser University, Canada
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Qin Jin, Renmin University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Qiuqiang Kong, ByteDance, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Rebecca Fiebrink, University of London, UK
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Rick Taube, University of Illinois at Urbana-Champaign, USA
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Roger Dannenberg, Carnegie Mellon University, USA
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Rongfeng Li, Beijing University of Posts and Telecommunications, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Rui Wang, Institute of Information Engineering, Chinese Academy of Sciences, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Ruihua Song, Renmin University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Shangfei Wang, University of Science and Technology of China, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Shasha Mao, Xidian University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Shiguang Shan, Institute of Computing Technology, Chinese Academy of Sciences, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Shiqi Wang, City University of Hong Kong, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Shun Kuremoto，Uchida Yoko Co.,Ltd，Japan
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Si Liu, Beihang University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Simon Lui, Huawei Technologies Co., Ltd, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Tiange Zhou, NetEase Cloud Music, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Weibei Dou, Tsinghua University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Weiming Dong, Institute of Automation, Chinese Academy of Sciences, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Wei-Ta Chu, National Chung Cheng University, Taiwan, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Wei Li, Fudan University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Weiwei Zhang, Dalian Maritime University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Wei Zhong, China University of Communication, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Wen-Huang Cheng, National Chiao Tung University, Taiwan, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Wenli Zhang, Beijing University of Technology, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Xi Shao, Nanjing University of Posts and Telecommunications, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Xiaojing Liang, NetEase Cloud Music, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Xiaopeng Hong, Harbin Institute of Technology, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Xiaoyan Sun, University of Science and Technology of China, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Xiaoying Zhang, China Rehabilitation Research Center, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Xihong Wu, Peking University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Xinfeng Zhang, University of Chinese Academy of Sciences, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Xu Tan, Microsoft Research Asia, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Yanchao Bi, Beijing Normal University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Yi Qin, Shanghai Conservatory of Music, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Ying-Qing Xu, Tsinghua University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Yirui Wu, Hohai University, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Yuanchun Xu, Xiaoice, China
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  Zhiyao Duan, University of Rochester, USA
                </div>
              </li>

          </h5>
        </div>
      </div>
    </div>
  </section>

  <section id="ppl">
    <div class="container">
      <div class="row">
        <div class="col-lg-12 text-center">
          <h2 class="section-heading">Organizing Team</h2>
          <hr class="my-4">
        </div>
      </div>
    </div>
    <div class="container">
      <div class="row">
        <!-- Luntian Mou -->
        <div class="col-lg-6 col-md-8 text-center">
          <div class="service-box mt-5 mx-auto">
            <img class="mb-3" src="images/Luntian_Mou.jpeg" style="height: 200px; border-radius: 20px;" />

            <h5 class="mb-3"><a target="_blank" rel="noopener noreferrer" href="mailto:ltmou@bjut.edu.cn"
                style="color: black;">Luntian Mou</a></h5>

            <p class="text-muted mb-0" style="font-size: 0.9em;">Beijing University of Technology</p>
            <p class="text-muted mb-0" style="font-size: 0.9em;">Beijing, China</p>
            <a href="mailto:ltmou@bjut.edu.cn" target="_blank">
              <p class="text-muted mb-0" style="font-size: 0.9em;">ltmou@bjut.edu.cn</p>
            </a>
            <br>

            <p class="text-muted mb-0" style="font-size: 0.9em; " align="left">Dr. Luntian Mou is an Associate Professor with Beijing Institute of Artificial Intelligence (BIAI), the Faculty of Information Technology, Beijing University of Technology. He was a Visiting Scholar with the University of California, Irvine, from 2019 to 2020. And he was a Postdoctoral Fellow at Peking University, from 2012 to 2014. He initiated the IEEE Workshop on Artificial Intelligence for Art Creation (AIART) in 2019, and has organized the workshop ever since. His current research interests include artificial intelligence, machine learning, affective computing, multimedia computing, brain-like computing, and neuroscience. And he serves as a Co-Chair of System subgroup in AVS workgroup. He is a Senior Member of IEEE and CCF, and a Member of ACM, CAAI, and CSIG, and an Expert of MPEG China.</p>
          </div>
        </div>
        <!-- Feng Gao -->
        <div class="col-lg-6 col-md-8 text-center">
          <div class="service-box mt-5 mx-auto">
            <img class="mb-3" src="images/Feng_Gao.jpeg" style="height: 200px; border-radius: 20px;" />
            <h5 class="mb-3"><a target="_blank" rel="noopener noreferrer" href="mailto:gaofeng2018@tsinghua.edu.cn"
                style="color: black;">Feng Gao</a></h5>
            <p class="text-muted mb-0" style="font-size: 0.9em;">Peking University</p>
            <p class="text-muted mb-0" style="font-size: 0.9em;">Beijing, China</p>
            <a href="mailto:gaofeng2018@tsinghua.edu.cn" target="_blank">
              <p class="text-muted mb-0" style="font-size: 0.9em;">gaof@pku.edu.cn</p>
            </a>
            <br>

            <p class="text-muted mb-0" style="font-size: 0.9em; " align="left">Dr. Feng Gao is an Assistant Professor with the School of Arts, Peking University. He has long researched in the disciplinary fields of AI and art, especially in AI painting. He co-initiated the international workshop of AIART. Currently, he is also enthusiastic in virtual human. He has demonstrated his AI painting system, called Daozi, in several workshops and drawn much attention. </p>
          </div>
        </div>
        <!-- Kejun Zhang -->
        <div class="col-lg-6 col-md-8 text-center">
          <div class="service-box mt-5 mx-auto">
            <img class="mb-3" src="images/Kejun_Zhang.jpg" style="height: 200px; border-radius: 20px;" />
            <h5 class="mb-3"><a target="_blank" rel="noopener noreferrer" href="https://person.zju.edu.cn/en/zhangkejun"
                style="color: black;">Kejun Zhang</a></h5>
            <p class="text-muted mb-0" style="font-size: 0.9em;">Zhejiang University</p>
            <p class="text-muted mb-0" style="font-size: 0.9em;">Hangzhou, China</p>
            <a href="mailto:zhangkejun@zju.edu.cn" target="_blank">
              <p class="text-muted mb-0" style="font-size: 0.9em;">zhangkejun@zju.edu.cn</p>
            </a>
            <br>

            <p class="text-muted mb-0" style="font-size: 0.9em; " align="left">Dr. Kejun Zhang is a Professor with Zhejiang University, joint PhD supervisor on Design and Computer Science, Dean of Department of Industrial Design at College of Computer Science of Zhejiang University. He received his PhD degree from College of Computer Science and Technology, Zhejiang University in 2010. From 2008 to 2009, He was a visiting research scholar of University of Illinois at Urbana-Champaign, USA. In June 2013, he became a faculty of the College of Computer Science and Technology at Zhejiang University. His current research interests include Affective Computing，Design Science, Artificial Intelligence, Multimedia Computing and the understanding, modelling and innovation design of products and social management by computational means. He is now the PI of National Science Foundation of China, Co-PI of National Key Research and Development Program of China, and PIs of ten more other research programs. He has authored 4 books, more than 40 scientific papers.</p>
          </div>
        </div>
        <!-- Jiaying Liu -->
        <div class="col-lg-6 col-md-8 text-center">
          <div class="service-box mt-5 mx-auto">
            <a href="http://39.96.165.147/people/liujiaying.html">
              <img class="mb-3" src="images/Jiaying_Liu.jpeg" style="height: 200px; border-radius: 20px;" />
            </a>

            <h5 class="mb-3"><a target="_blank" rel="noopener noreferrer"
                href="http://39.96.165.147/people/liujiaying.html" style="color: black;">Jiaying Liu</a></h5>
            <p class="text-muted mb-0" style="font-size: 0.9em;">Peking University</p>
            <p class="text-muted mb-0" style="font-size: 0.9em;">Beijing, China</p>
            <a href="mailto:liujiaying@pku.edu.cn" target="_blank">
              <p class="text-muted mb-0" style="font-size: 0.9em;">liujiaying@pku.edu.cn</p>
            </a>
            <br>

            <p class="text-muted mb-0" style="font-size: 0.9em; " align="left">Dr. Jiaying Liu is currently an Associate Professor with the Wangxuan Institute of Computer Technology, Peking University. She received the Ph.D. degree (Hons.) in computer science from Peking University, Beijing China, 2010. She has authored over 100 technical articles in refereed journals and proceedings, and holds 43 granted patents. Her current research interests include multimedia signal processing, compression, and computer vision. Dr. Liu is a Senior Member of IEEE, CSIG and CCF. She was a Visiting Scholar with the University of Southern California, Los Angeles, from 2007 to 2008. She was a Visiting Researcher with the Microsoft Research Asia in 2015 supported by the Star Track Young Faculties Award. She has served as a member of Membership Services Committee in IEEE Signal Processing Society, a member of Multimedia Systems & Applications Technical Committee (MSA TC), Visual Signal Processing and Communications Technical Committee (VSPC TC) in IEEE Circuits and Systems Society, a member of the Image, Video, and Multimedia (IVM) Technical Committee in APSIPA. She received the IEEE ICME 2020 Best Paper Awards and IEEE MMSP 2015 Top10% Paper Awards. She has also served as the Associate Editor of IEEE Trans. on Image Processing, and Elsevier JVCI, the Technical Program Chair of IEEE VCIP-2019/ACM ICMR-2021, the Publicity Chair of IEEE ICME-2020/ICIP-2019, and the Area Chair of CVPR-2021/ECCV-2020/ICCV-2019. She was the APSIPA Distinguished Lecturer (2016-2017).</p>
          </div>
        </div>
        <!-- Ling Fan -->
        <div class="col-lg-6 col-md-8 text-center">
          <div class="service-box mt-5 mx-auto">
            <img class="mb-3" src="images/Ling_Fan.jpg" style="height: 200px; border-radius: 20px;" />

            <h5 class="mb-3"><a target="_blank" rel="noopener noreferrer" href="mailto:lfan@tongji.edu.cn"
                style="color: black;">Ling Fan</a></h5>

            <p class="text-muted mb-0" style="font-size: 0.9em;">Tezign.com</p>
            <p class="text-muted mb-0" style="font-size: 0.9em;">Tongji University Design Artificial Intelligence Lab
            </p>
            <p class="text-muted mb-0" style="font-size: 0.9em;">Shanghai, China</p>
            <a href="mailto:lfan@tongji.edu.cn" target="_blank">
              <p class="text-muted mb-0" style="font-size: 0.9em;">lfan@tongji.edu.cn</p>
            </a>
            <br>

            <p class="text-muted mb-0" style="font-size: 0.9em; " align="left">Dr. Ling Fan is a Scholar and Entrepreneur to bridge machine intelligence with creativity. He is the founding chair and professor of Tongji University Design Artificial Intelligence Lab. Before, he held teaching position at the University of California at Berkeley and China Central Academy of Fine Arts. Dr. Fan co-founded Tezign.com, a leading technology start-up with the mission to build digital infrastructure for creative contents. Tezign is backed by top VCs like Sequoia Capital and Hearst Ventures. Dr. Fan is a World Economic Forum Young Global Leader, an Aspen Institute China Fellow, and Youth Committee member at the Future Forum. He is also a member of IEEE Global Council for Extended Intelligence. Dr. Fan received his doctoral degree from Harvard University and master's degree from Princeton University. He recently published From Universality of Computation to the Universality of Imagination, a book on how machine intelligence would influence human creativity.</p>
          </div>
        </div>
        <!-- Zeyu Wang -->
        <div class="col-lg-6 col-md-8 text-center">
          <div class="service-box mt-5 mx-auto">
            <a href="http://cislab.hkust-gz.edu.cn/members/zeyu-wang/">
              <img class="mb-3" src="images/zeyuwang.jpeg" style="height: 200px; border-radius: 20px;" />
            </a>

            <h5 class="mb-3"><a target="_blank" rel="noopener noreferrer"
                href="http://cislab.hkust-gz.edu.cn/members/zeyu-wang/" style="color: black;">Zeyu Wang</a></h5>

            <!-- <p class="text-muted mb-0" style="font-size: 0.9em;">Tezign.com</p> -->
            <p class="text-muted mb-0" style="font-size: 0.9em;">Hong Kong University of Science and <br> Technology
              (Guangzhou) </p>
            <p class="text-muted mb-0" style="font-size: 0.9em;">Guangzhou, China</p>
            <a href="mailto:zeyuwang@ust.hk" target="_blank">
              <p class="text-muted mb-0" style="font-size: 0.9em; ">zeyuwang@ust.hk</p>
            </a>
            <br>

            <p class="text-muted mb-0" style="font-size: 0.9em; " align="left">Dr. Zeyu Wang is an Assistant Professor of Computational Media and Arts (CMA) in the Information Hub at the Hong Kong University of Science and Technology (Guangzhou) and an Affiliate Assistant Professor in the Department of Computer Science and Engineering at the Hong Kong University of Science and Technology. He received a PhD from the Department of Computer Science at Yale University and a BS from the School of Artificial Intelligence at Peking University. He leads the Creative Intelligence and Synergy (CIS) Lab at HKUST(GZ) to study the intersection of Computer Graphics, Human-Computer Interaction, and Artificial Intelligence, with a focus on algorithms and systems for digital content creation. His current research topics include sketching, VR/AR/XR, and generative techniques, with applications in art, design, perception, and cultural heritage. His work has been recognized by an Adobe Research Fellowship, a Franke Interdisciplinary Research Fellowship, a Best Paper Award, and a Best Demo Honorable Mention Award.</p>
          </div>
        </div>
        <!-- Nick Bryan-Kinns -->
        <div class="col-lg-6 col-md-8 text-center">
          <div class="service-box mt-5 mx-auto">
            <a href="https://nickbknickbk.github.io/">
              <img class="mb-3" src="images/Nick-Bryan-Kinns.jpg" style="height: 200px; border-radius: 20px;" />
            </a>

            <h5 class="mb-3"><a target="_blank" rel="noopener noreferrer" href="https://nickbknickbk.github.io/"
                style="color: black;">Nick Bryan-Kinns</a></h5>

            <p class="text-muted mb-0" style="font-size: 0.9em;">University of the Arts London</p>
            <p class="text-muted mb-0" style="font-size: 0.9em;">London, UK</p>
            <a href="mailto:n.bryankinns@arts.ac.uk" target="_blank">
              <p class="text-muted mb-0" style="font-size: 0.9em;">n.bryankinns@arts.ac.uk</p>
            </a>
            <br>

            <p class="text-muted mb-0" style="font-size: 0.9em; " align="left">Dr. Nick Bryan-Kinns is a Professor of Creative Computing at the Creative Computing Institute, University of the Arts London. His research explores new approaches to interactive technologies for the Arts and the Creative Industries through Creative Computing. His current focus is on Human-Centered AI and eXplainable AI for the Arts. His research has made audio engineering more accessible and inclusive, championed the design of sustainable and ethical IoT and wearables, and engaged rural and urban communities with physical computing through craft and cultural heritage. Products of his research have been exhibited internationally including Ars Electronica (Austria) the V&A and the Science Museum (UK), made available online and as smartphone apps, used by artists and musicians in performances and art installations, and have been reported in public media outlets including the BBC and New Scientist. He is a Fellow of the Royal Society of Arts, Fellow of the British Computer Society (BCS), and Senior Member of the Association of Computing Machinery (ACM). He is a recipient of the ACM and BCS Recognition of Service Awards, and chaired the ACM Creativity and Cognition conference 2009, and the BCS international HCI conference 2006.</p>
          </div>
        </div>
        <!-- Ambarish Natu -->
        <div class="col-lg-6 col-md-8 text-center">
          <div class="service-box mt-5 mx-auto">
            <a href="https://www.linkedin.com/in/ambarishnatu/">
              <img class="mb-3" src="images/Ambarish_Natu.jpg" style="height: 200px; border-radius: 20px;" />
            </a>

            <h5 class="mb-3"><a target="_blank" rel="noopener noreferrer" href="https://www.linkedin.com/in/ambarishnatu/"
                style="color: black;">Ambarish Natu</a></h5>

            <p class="text-muted mb-0" style="font-size: 0.9em;">Australian Government</p>
            <p class="text-muted mb-0" style="font-size: 0.9em;">Australian Capital Territory, Australia</p>
            <a href="mailto:ambarish.natu@gmail.com" target="_blank">
              <p class="text-muted mb-0" style="font-size: 0.9em;">ambarish.natu@gmail.com</p>
            </a>
            <br>

            <p class="text-muted mb-0" style="font-size: 0.9em; " align="left">Dr. Ambarish Natu is with the Australian Government. After graduating from University of New South Wales, Sydney, Ambarish has held positions as a visiting researcher in Italy and Taiwan, worked for industry in United Kingdom and the United States of America and for the past ten years has been working in the Australian Government. For the past 17 years, Ambarish has led the development of five international standards under the auspices of the International Standards Organization (ISO) popularly known as JPEG (Joint Photographic Experts Group). He is the recipient of the ISO/IEC certificate for contributions to technology standards. Ambarish is highly active in the area of international standardization and voicing Australian concerns in the area of JPEG and MPEG (Motion Pictures Experts Group) standardization. He previously initiated an effort in the area of standardization relating to Privacy and Security in the Multimedia Context both within JPEG and MPEG standard bodies. In 2015, Ambarish was the recipient of the prestigious Neville Thiele Award and the Canberra Professional Engineer of the Year by Engineers Australia. Ambarish currently works as an ICT Specialist for the Australian Government. Ambarish is a Fellow of the Australian Computer Society and Engineers Australia. Ambarish also serves on the IVMSP TC and the Autonomous Systems Initiative of the IEEE Signal Processing Society. Ambarish has also been General Chair of DICTA 2018, ICME 2023 and TENSYMP 2023 in the past. Ambarish has keen interest in next generation data and analytics technologies that will change the course of the way we interact with in the world.</p>
          </div>
        </div>



      </div>
    </div>
  </section>

  <section class="bg-primary" id="history">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading text-white">History</h2>
          <hr class="light my-4">

          <h5 class="section-heading text-white" style="text-align: left; line-height: 1.8">
            <ul>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  AIART 2019: <a href="https://aiart2019.github.io/" target="_blank">https://aiart2019.github.io/</a>
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  AIART 2020: <a href="https://aiart2020.github.io/" target="_blank">https://aiart2020.github.io/</a>
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  AIART 2021: <a href="https://aiart2021.github.io/" target="_blank">https://aiart2021.github.io/</a>
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  AIART 2022: <a href="https://aiart2022.github.io/" target="_blank">https://aiart2022.github.io/</a>
                </div>
              </li>
              <li style="color: white;">
                <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
                  AIART 2023: <a href="https://aiart2023.github.io/" target="_blank">https://aiart2023.github.io/</a>
                </div>
              </li>
          </h5>
        </div>
      </div>
    </div>
  </section>

  <section id="MIR">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading">Partner: Machine Intelligence Research</h2>
          <hr class="dark my-4">
          <div class="text-muted" style="text-align: left;color: black;font-size: 18px;line-height: 1.8"> Machine
            Intelligence Research (original title: International Journal of Automation and Computing), published by
            Springer, and sponsored by Institute of Automation, Chinese Academy of Sciences, is formally released in
            2022. The journal publishes high-quality papers on original theoretical and experimental research, targets
            special issues on emerging topics and specific subjects, and strives to bridge the gap between theoretical
            research and practical applications. The journal has been indexed by ESCI, EI, Scopus, CSCD, etc.</div>
          <br>

          <ul>
            <li style="color: black;">
              <div class="text-muted" style="text-align: left;color: black;font-size: 18px;line-height: 1.8">
                MIR official websites:
                <ul>
                  <li>
                    <a style="text-align: left" href="https://www.springer.com/journal/11633"
                      target="_blank">https://www.springer.com/journal/11633</a>
                  </li>
                  <li>
                    <a style="text-align: left" href="https://www.mi-research.net"
                      target="_blank">https://www.mi-research.net</a>
                  </li>
                </ul>
              </div>
            </li>
            <li style="color: black;">
              <div class="text-muted" style="text-align: left;color: black;font-size: 18px;line-height: 1.8">
                MIR Editor-in-Chief - Tan Tieniu, Institute of Automation, Chinese Academy of Sciences
              </div>
            </li>
            <li style="color: black;">
              <div class="text-muted" style="text-align: left;color: black;font-size: 18px;line-height: 1.8">
                MIR Associate Editors-in-Chief
                <ul>
                  <li>
                    <a> Liang Wang, Chinese Academy of Sciences, China
                  </li>
                  <li>
                    <a> Yike Guo, Imperial College London, UK
                  </li>
                  <li>
                    <a> Brian C. Lovell, The University of Queensland, Australia
                  </li>
                </ul>
              </div>
            </li>

          </ul>

        </div>
      </div>
    </div>
  </section>

  <section class="bg-primary" id="sponsorship">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading text-white">Call For Sponsorship</h2>
          <hr class="light my-4">

          <h5 class="section-heading text-white" style="text-align: left; line-height: 1.8">

            <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">

              <strong>Platinum Level (RMB￥100,000)</strong><br>
              - 4 free registrations (or including up to 4 full registration)<br>
              - Invitation to give an industry keynote speech<br>
              - Logo on AIART 2024 official website with description and link to sponsor website<br>
              - Logo on workshop handbook and presentation material (under Platinum Level)<br>
              - One on one negotiation for special requirements.<br><br>

              <strong>Gold Level (RMB￥50,000)</strong><br>
              - 2 free registrations (or including up to 2 full registration)<br>
              - Participation in related industry panel<br>
              - Logo on AIART 2024 official website with short description and link to sponsor website<br>
              - Logo on workshop handbook and presentation material (under Gold Level)<br>
              - One on one negotiation for special requirements.<br><br>

              <strong>Silver Level (RMB￥20,000)</strong><br>
              - 1 free registration (or including up to 1 full registration)<br>
              - Logo on AIART 2024 official website with link to sponsor website<br>
              - Logo on workshop handbook and presentation material (under Silver Level)<br><br>

            </div>

          </h5>
          <!-- <br><br>
          <a href="https://www.tezign.com">
            <img src="images/tz-logo.png" style="max-width: 50%; text-align:center; " />
          </a>
          <br><br><br>


          <h5 class="section-heading text-white" style="text-align: left; line-height: 1.8">

            <div class="text-faded" style="text-align: left;color: white;font-size: 18px;line-height: 1.8">
              Tezign has the vision Technology Empowers Imagination. Founded in 2015, Tezign aims to build the digital
              infrastructure of content experience. Tezign provides a digital platform based on enterprise content
              workflow, connecting content production, management and application, to help brands drive growth with
              content. <br><br>

              Tezign has raised the D1 round of financing and become the only Contech unicorn enterprise with a
              valuation of more than US $1 billion. Tezign is backed by world recognized investors including Temasek,
              Sequoia Capital, Hearst Ventures, among others. Tezign has partnered with more than 200 medium to large
              enterprises such as Alibaba, Unilever, ByteDance, PepsiCo, Shiseido, P&G, Starbucks, McDonald's, Heinz,
              Mars, Budweiser, Adidas, Xtep, Ubras, Lenovo, Midea, Tencent, L'Oreal, Danone, Porsche, Audi, Volvo,
              Aptar, Bosch, Stanley Black & Decker etc to upgrade their content strategies. It has produced more than
              150,000 creative content assets and formed a one hundred million level content asset management scale.
              Tezign's content ecosystem has gathered more than 50,000 content creators. <br><br>

              Tezign was a National Industrial Design Center issued by the Ministry of industry and information
              technology, awarded as TOP.1 in China in the list of The Information 50 startups, Fast Company top 50 of
              China's best innovative companies, Forbes High Growth Gazelle, Forbes China Top 10 intelligent design
              enterprises, Hurun Group List of Global Unicorn, and was named by Forrester, a leading independent global
              technology and market research company, in the Research Report "Now Tech: Marketing Resource Management,
              Q12022" (MRM) as the only MRM vendor in the contech segment Asia Pacific. <br><br>

              On 6th-7th May 2023, Tezign will launch the AIGC Builder and Creator Conference in Shanghai, to create
              maximum two-way interaction among AIGC creators and builders in various quality forms. Stay tuned by
              following the official Wechat account: Who is AIGC. <br>
            </div>

          </h5> -->
        </div>
      </div>
    </div>
  </section>


  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>
  <script src="vendor/scrollreveal/scrollreveal.min.js"></script>
  <script src="vendor/magnific-popup/jquery.magnific-popup.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="js/creative.min.js"></script>

</body>

</html>